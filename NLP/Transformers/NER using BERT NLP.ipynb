{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER using BERT NLP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNVjK7A3jBUN1Ngv/0d4w44"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0cf78d098d984613ab0f7d69129f5602":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2d55522376664a368c1373e643af5192","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e608fa750bf408ead1670257b99e63a","IPY_MODEL_c67bb60736a34b02ab3ca8ea95d25c1b","IPY_MODEL_fcbb4392bd5f40cd8f6c0de84df565db"]}},"2d55522376664a368c1373e643af5192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e608fa750bf408ead1670257b99e63a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45f471d8855c4bcaa0edea07f60f8737","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ab3838b33f74462af2f58e053891aad"}},"c67bb60736a34b02ab3ca8ea95d25c1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86f9652a7fdc4f0fb2ad5c35af4ad8c5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35a971d42852406e80500b21fa4af004"}},"fcbb4392bd5f40cd8f6c0de84df565db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e23abc8980164770865430390dcc92ef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 12.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a75856daa0b74be68053c18e95a7798a"}},"45f471d8855c4bcaa0edea07f60f8737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ab3838b33f74462af2f58e053891aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86f9652a7fdc4f0fb2ad5c35af4ad8c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"35a971d42852406e80500b21fa4af004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e23abc8980164770865430390dcc92ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a75856daa0b74be68053c18e95a7798a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba7d796869944560a6a1615e2bc43d69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2791b51cdcde4721922fc36c71656353","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9744c70108fd4a5eac9006bf3cd2531b","IPY_MODEL_dbc3d44eef39424590c3b7cfcd4b2ba0","IPY_MODEL_8a9927388f904563b9526bb245bdc707"]}},"2791b51cdcde4721922fc36c71656353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9744c70108fd4a5eac9006bf3cd2531b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41fb211b05824bf0a694efd041499314","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d04bc59858164f2ebfb5aed4b7af4d1a"}},"dbc3d44eef39424590c3b7cfcd4b2ba0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db99b5d4c5a24b898f55db0e312590d3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":672271273,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":672271273,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e90e24737bc4ca2804718c046afebf8"}},"8a9927388f904563b9526bb245bdc707":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a8bf9626eec64a2dbe9e72e07f5f93c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 641M/641M [00:20&lt;00:00, 38.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8052e333b3364d0aaffad0357d977f61"}},"41fb211b05824bf0a694efd041499314":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d04bc59858164f2ebfb5aed4b7af4d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db99b5d4c5a24b898f55db0e312590d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e90e24737bc4ca2804718c046afebf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8bf9626eec64a2dbe9e72e07f5f93c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8052e333b3364d0aaffad0357d977f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4eb51dac38e04da889fdbc9260b8e8a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e01822a63044e16ae4ee1b2691ef41a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fe77dec808524416ae6f1f4dd37d1ae3","IPY_MODEL_1c90c2f1695a4b98a27f4bb16944fedd","IPY_MODEL_ae501e3e3e3b412787cf28c0bda79f56"]}},"7e01822a63044e16ae4ee1b2691ef41a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe77dec808524416ae6f1f4dd37d1ae3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2bf3f5eab7a4f80b2d107ad1d3dc4b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4a8f4082df94036b34c8c225f0fc67b"}},"1c90c2f1695a4b98a27f4bb16944fedd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_21f556a4b0ce4e02a737dd166d167bee","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b4af95272f445e1b2993d858cf9c853"}},"ae501e3e3e3b412787cf28c0bda79f56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a10f8d877ebd4402be48ebc759521e4b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 661B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb3f5c30691f4446a021b883c7a85620"}},"b2bf3f5eab7a4f80b2d107ad1d3dc4b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4a8f4082df94036b34c8c225f0fc67b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21f556a4b0ce4e02a737dd166d167bee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b4af95272f445e1b2993d858cf9c853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a10f8d877ebd4402be48ebc759521e4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb3f5c30691f4446a021b883c7a85620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd57798ff0ca478dbd57f7a8726e3e40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_08795d2b35184bb08ae695c6e93c1ef7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c2173252a0f472ea15a0a77c0626e1b","IPY_MODEL_907e9ef69dec43829e9b07d08d65a52c","IPY_MODEL_70ad7f7331f143949b0df3ca2c7818f5"]}},"08795d2b35184bb08ae695c6e93c1ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c2173252a0f472ea15a0a77c0626e1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5a7835728353463593caa99f26e50698","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_148198ae0db94bd585fc7bdd422756a6"}},"907e9ef69dec43829e9b07d08d65a52c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_773df2a52c6f4ce8a03b707f7f174ee2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":871891,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":871891,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_314729857f914bbfa755627d6f59ceb2"}},"70ad7f7331f143949b0df3ca2c7818f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e018c2b59d94e74b5d7d37a67008218","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 851k/851k [00:00&lt;00:00, 10.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05284ab29c2445a381fd4a442d7f017a"}},"5a7835728353463593caa99f26e50698":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"148198ae0db94bd585fc7bdd422756a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"773df2a52c6f4ce8a03b707f7f174ee2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"314729857f914bbfa755627d6f59ceb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e018c2b59d94e74b5d7d37a67008218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05284ab29c2445a381fd4a442d7f017a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ca25ea8f19b4939a62679a2ff380b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5940d10732b945b0aeea6fa7a5737d4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_689a4644476a4925be9d8b5766110c88","IPY_MODEL_6b5cb0069a1f4d8e9aad7de30f32c732","IPY_MODEL_d56c08f2ea63456f9beaadbf5a92aab5"]}},"5940d10732b945b0aeea6fa7a5737d4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"689a4644476a4925be9d8b5766110c88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebbbcbd5438b4b3bb73c906d4d68dc76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b20abd61fd54282ace1f20536a178b2"}},"6b5cb0069a1f4d8e9aad7de30f32c732":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a10e95812224ad594066f9875e2be7e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1715180,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1715180,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a88eddf833bb4ba8b90170164469d8ed"}},"d56c08f2ea63456f9beaadbf5a92aab5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4cb41d3bd03f44acab305bdff02be5ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.64M/1.64M [00:00&lt;00:00, 15.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0c236af2a134e72a7784de780133c06"}},"ebbbcbd5438b4b3bb73c906d4d68dc76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b20abd61fd54282ace1f20536a178b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a10e95812224ad594066f9875e2be7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a88eddf833bb4ba8b90170164469d8ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4cb41d3bd03f44acab305bdff02be5ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0c236af2a134e72a7784de780133c06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54a70952f63541eaa8397b23d9171a27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_03ad2b9908ca47f6973a8c86a2225fe3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9bfe8b81bc9d46908592bef52924ca92","IPY_MODEL_61846d244f2c4a59bd4e3a0f658044eb","IPY_MODEL_0e3298d501e14660b768145d92aa9f79"]}},"03ad2b9908ca47f6973a8c86a2225fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bfe8b81bc9d46908592bef52924ca92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d494d647f4c34014a106f7bf40e91d1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44f937915cd14d50990af7f2169fe73a"}},"61846d244f2c4a59bd4e3a0f658044eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_21d39d1c1d2c4a0494dde2437fd52519","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_892d735c68d2482191f9722db25a404b"}},"0e3298d501e14660b768145d92aa9f79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d131328414241ee99e084fbcd6dd84b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 4.08MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47a7da967e3d485f84eee8ba49d84ca8"}},"d494d647f4c34014a106f7bf40e91d1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"44f937915cd14d50990af7f2169fe73a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21d39d1c1d2c4a0494dde2437fd52519":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"892d735c68d2482191f9722db25a404b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d131328414241ee99e084fbcd6dd84b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47a7da967e3d485f84eee8ba49d84ca8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"027c9fb342f94f508991bbda641476d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9a7fcc16b08a4dc782d8b53f0a8f1495","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_591df1ada8614553a82b66972d56f426","IPY_MODEL_2d8ca72fb6c240f2a166ed9a6c05ec5a","IPY_MODEL_0ea6a461017c45688d793d2a62692f43"]}},"9a7fcc16b08a4dc782d8b53f0a8f1495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"591df1ada8614553a82b66972d56f426":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_621bb7f851594dfa96b620586ba7d856","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c8bf42b7e814b56a796ba6bd839ad02"}},"2d8ca72fb6c240f2a166ed9a6c05ec5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f0ac25364149410385f8bbd4ef6513a3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_641b4b5a24874b75b3fe19d625461fba"}},"0ea6a461017c45688d793d2a62692f43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ddc9ac01016c4d3e9d476e896f607897","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 14.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe55b84eb2c04f25a99fbb2314e7e672"}},"621bb7f851594dfa96b620586ba7d856":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6c8bf42b7e814b56a796ba6bd839ad02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0ac25364149410385f8bbd4ef6513a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"641b4b5a24874b75b3fe19d625461fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ddc9ac01016c4d3e9d476e896f607897":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe55b84eb2c04f25a99fbb2314e7e672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8574e59bd09d41d0a1cfdd0ca05d5c44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cffb4cee9a8949f1a0c3945f23f22c75","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_69a5375a3b5248b68f3d6efc7050ee46","IPY_MODEL_11e5602d71ef4783b59b549cdb3dccfd","IPY_MODEL_26d3ee2a0c534a019dd62906cc978473"]}},"cffb4cee9a8949f1a0c3945f23f22c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69a5375a3b5248b68f3d6efc7050ee46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ed69e9a0915646f2b2d876d5de86bbfe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3f525956be142d491fa5e0d78d8590d"}},"11e5602d71ef4783b59b549cdb3dccfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96f1cedad03a407eaa5fe6ae7e6b0485","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29d658a89ae64f4e831b34f1aaf5afcc"}},"26d3ee2a0c534a019dd62906cc978473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6b8d068030e743939b0138bb26a53388","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:07&lt;00:00, 55.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3e782a62c054a529aa386624ec515e8"}},"ed69e9a0915646f2b2d876d5de86bbfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a3f525956be142d491fa5e0d78d8590d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96f1cedad03a407eaa5fe6ae7e6b0485":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29d658a89ae64f4e831b34f1aaf5afcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b8d068030e743939b0138bb26a53388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f3e782a62c054a529aa386624ec515e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Basic Name enity Recognition with BERT \n","bert is one of the most poerful NLP tools in the world right now here we will be looking at some of its out of the box features for Name Entity Recognition also known as NER - \n","<br/>\n","<br/>\n","source - \n","https://towardsdatascience.com/easy-fine-tuning-of-transformers-for-named-entity-recognition-d72f2b5340e3 "],"metadata":{"id":"mU1FUngDtEJ6"}},{"cell_type":"markdown","source":["we will go through how to easily fine-tune any pretrained Natural Language Processing (=NLP) transformer for Named-Entity Recognition (=NER) in any language.\n","Why should you care? Well, NER is a powerful NLP task with many applications, as has been thoroughly described on Towards Data Science. However, effectively using NER often requires language or domain specific fine-tuning of your NER model based on the pretrained transformers that are available and realistic to use given your compute budget.\n","To show you how to do just that, we use the python package NERDA to fine-tune a BERT transformer for NER.\n","NERDA is a general purpose NER-system that can be used for fine-tuning any transformer for NER in any language with a minimum of code."],"metadata":{"id":"dqYWmhxTx3XO"}},{"cell_type":"markdown","source":["#Named-Entity Recognition for Starters\n","If you are not familiar with NER, look to the Wikipedia definition:\n","Named-entity recognition (also known as (named) entity identification, entity chunking, and entity extraction) is a Natural Language Processing subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n","We can illustrate this further with an example of a NER task.\n","TASK: Identify person names and organizations in text:\n","Jim bought 300 shares of Acme Corp.\n","SOLUTION: Persons: ‘Jim’, Organizations: ‘Acme Corp.’\n","To get an introduction to the other concepts and technologies mentioned in this article we have listed a number of previous Towards Data Science stories in the Resources section."],"metadata":{"id":"6lHlUagIx7zD"}},{"cell_type":"markdown","source":["#Toolset\n","Now, let us turn to actually fine-tuning a transformer for NER.\n","The steps we show you are the same regardless of your choice of transformer and target language.\n","We will utilize the new python package NERDA for the job."],"metadata":{"id":"OuAP27Qhx_k6"}},{"cell_type":"markdown","source":["NERDA has an easy-to-use interface for fine-tuning NLP transformers for Named-Entity Recognition tasks. It builds on the popular machine learning framework PyTorch and Hugging Face transformers.\n","NERDA is open-sourced and available on the Python Package Index (PyPI). It can be installed with:"],"metadata":{"id":"ufg9m1P5yIc1"}},{"cell_type":"code","source":["!pip install NERDA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXXUa7oQtdEN","executionInfo":{"status":"ok","timestamp":1642418733201,"user_tz":300,"elapsed":10742,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"e6a30634-83c3-4a68-e6b5-3dbc4c58d319"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting NERDA\n","  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n","Collecting pyconll\n","  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n","Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 41.9 MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from NERDA) (3.2.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from NERDA) (1.1.5)\n","Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from NERDA) (1.10.0+cu111)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from NERDA) (0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->NERDA) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->NERDA) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->NERDA) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->NERDA) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->NERDA) (3.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->NERDA) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (4.10.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 22.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 24.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (3.4.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->NERDA) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->NERDA) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->NERDA) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->NERDA) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->NERDA) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->NERDA) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->NERDA) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->NERDA) (7.1.2)\n","Building wheels for collected packages: progressbar\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=7bc7af3214d5dbc1b4224e16b08934ff08ad4b7c1284a44eb15010bef5f39021\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","Successfully built progressbar\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, pyconll, progressbar, NERDA\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed NERDA-1.0.0 huggingface-hub-0.4.0 progressbar-2.5 pyconll-3.1.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"markdown","source":["# Dataset\n","We will use the English CoNLL-2003 data set with NER annotations for training and validation of our model.\n","First we download the data set and load the predefined training and validation data splits."],"metadata":{"id":"sVIQOnvAyS5o"}},{"cell_type":"code","source":["import NERDA\n","from NERDA import datasets\n","from NERDA.datasets import get_conll_data\n","\n","datasets.download_conll_data()\n","training = get_conll_data('train')\n","validation = get_conll_data('valid')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZP6I3cpkyeBm","executionInfo":{"status":"ok","timestamp":1642419170921,"user_tz":300,"elapsed":2079,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"d7f19555-aadc-4e75-bc05-67080afb4380"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading https://data.deepai.org/conll2003.zip\n"]}]},{"cell_type":"markdown","source":["CoNLL-2003 operates with the following types of named entities (fairly standard categories):\n","* PERsons\n","* ORGanizations\n","* LOCations\n","* MISCellaneous\n","* Outside (not a named entity)\n","\n","\n","An observation from the CoNLL-2003 data set consists of a word-tokenized sentence with a named-entity tag for each of the word tokens.\n","Below you see an example of a random sentence from the CoNLL data set with its word-tokens coupled with their respective named-entity tags ([tag])."],"metadata":{"id":"zT_j_PuP0ELq"}},{"cell_type":"markdown","source":["    Germany [B-LOC]\n","    's [O]\n","    representative [O]\n","    to [O] \n","    the [O]\n","    European [B-ORG] \n","    Union [I-ORG] \n","    's [O]\n","    veterinary [O] \n","    committee [O]\n","    Werner [B-PER] \n","    Zwingmann [I-PER]\n","    said [O]\n","    on [O] \n","    Wednesday [O]\n","    ..."],"metadata":{"id":"oGGEBuaY0P2Y"}},{"cell_type":"markdown","source":["#Setting up the model\n","As a first step, we specify the available NER tags for the task (excluding the special ‘outside’ tag)."],"metadata":{"id":"XuwS9JpP0SYt"}},{"cell_type":"code","source":["tag_scheme = [\n","'B-PER',\n","'I-PER',\n","'B-ORG',\n","'I-ORG',\n","'B-LOC',\n","'I-LOC',\n","'B-MISC',\n","'I-MISC'\n","]"],"metadata":{"id":"zh1oT5zg0sFQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, we must decide, which transformer from Hugging Face transformers, we want to fine-tune. We will stick with an uncased multilingual BERT transformer (a popular choice).\n"],"metadata":{"id":"6k1L_7wy00XD"}},{"cell_type":"code","source":["transformer = 'bert-base-multilingual-uncased'"],"metadata":{"id":"35xKQ1NG02Pn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Also, we have the option to provide a selection of basic hyperparameters for the network as well as for the model training itself."],"metadata":{"id":"5zmDMjVh1LsZ"}},{"cell_type":"code","source":["# hyperparameters for network\n","dropout = 0.1\n","# hyperparameters for training\n","training_hyperparameters = {'epochs' : 4,'warmup_steps' : 500,'train_batch_size': 13,'learning_rate': 0.0001}"],"metadata":{"id":"sVutgmrc1Mzc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Putting the pieces together\n","Now, put the pieces together into a complete model configuration using the NERDA model interface."],"metadata":{"id":"Jb_ee9ee1mWH"}},{"cell_type":"code","source":["from NERDA.models import NERDA\n","\n","#set up the model\n","model = NERDA(\n","dataset_training = training,\n","dataset_validation = validation,\n","tag_scheme = tag_scheme, \n","tag_outside = 'O',\n","transformer = transformer,\n","dropout = dropout,\n","hyperparameters = training_hyperparameters\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266,"referenced_widgets":["0cf78d098d984613ab0f7d69129f5602","2d55522376664a368c1373e643af5192","0e608fa750bf408ead1670257b99e63a","c67bb60736a34b02ab3ca8ea95d25c1b","fcbb4392bd5f40cd8f6c0de84df565db","45f471d8855c4bcaa0edea07f60f8737","3ab3838b33f74462af2f58e053891aad","86f9652a7fdc4f0fb2ad5c35af4ad8c5","35a971d42852406e80500b21fa4af004","e23abc8980164770865430390dcc92ef","a75856daa0b74be68053c18e95a7798a","ba7d796869944560a6a1615e2bc43d69","2791b51cdcde4721922fc36c71656353","9744c70108fd4a5eac9006bf3cd2531b","dbc3d44eef39424590c3b7cfcd4b2ba0","8a9927388f904563b9526bb245bdc707","41fb211b05824bf0a694efd041499314","d04bc59858164f2ebfb5aed4b7af4d1a","db99b5d4c5a24b898f55db0e312590d3","8e90e24737bc4ca2804718c046afebf8","a8bf9626eec64a2dbe9e72e07f5f93c1","8052e333b3364d0aaffad0357d977f61","4eb51dac38e04da889fdbc9260b8e8a2","7e01822a63044e16ae4ee1b2691ef41a","fe77dec808524416ae6f1f4dd37d1ae3","1c90c2f1695a4b98a27f4bb16944fedd","ae501e3e3e3b412787cf28c0bda79f56","b2bf3f5eab7a4f80b2d107ad1d3dc4b1","a4a8f4082df94036b34c8c225f0fc67b","21f556a4b0ce4e02a737dd166d167bee","0b4af95272f445e1b2993d858cf9c853","a10f8d877ebd4402be48ebc759521e4b","fb3f5c30691f4446a021b883c7a85620","cd57798ff0ca478dbd57f7a8726e3e40","08795d2b35184bb08ae695c6e93c1ef7","9c2173252a0f472ea15a0a77c0626e1b","907e9ef69dec43829e9b07d08d65a52c","70ad7f7331f143949b0df3ca2c7818f5","5a7835728353463593caa99f26e50698","148198ae0db94bd585fc7bdd422756a6","773df2a52c6f4ce8a03b707f7f174ee2","314729857f914bbfa755627d6f59ceb2","3e018c2b59d94e74b5d7d37a67008218","05284ab29c2445a381fd4a442d7f017a","4ca25ea8f19b4939a62679a2ff380b1a","5940d10732b945b0aeea6fa7a5737d4c","689a4644476a4925be9d8b5766110c88","6b5cb0069a1f4d8e9aad7de30f32c732","d56c08f2ea63456f9beaadbf5a92aab5","ebbbcbd5438b4b3bb73c906d4d68dc76","8b20abd61fd54282ace1f20536a178b2","0a10e95812224ad594066f9875e2be7e","a88eddf833bb4ba8b90170164469d8ed","4cb41d3bd03f44acab305bdff02be5ff","c0c236af2a134e72a7784de780133c06"]},"id":"yvkxK_Hs18nR","executionInfo":{"status":"ok","timestamp":1642419754581,"user_tz":300,"elapsed":33433,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"4f7d5670-c0d4-456b-fefa-1342cc259160"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device automatically set to: cpu\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cf78d098d984613ab0f7d69129f5602","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba7d796869944560a6a1615e2bc43d69","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4eb51dac38e04da889fdbc9260b8e8a2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd57798ff0ca478dbd57f7a8726e3e40","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ca25ea8f19b4939a62679a2ff380b1a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":["#Under the hood \n","NERDA implements a torch neural network, that builds on the chosen transformer (in this case BERT). By default, the architecture of the network will be analogous to the one of the models in Hvingelby et al. 2020 (you can also provide your own network architecture, if you want).\n","In order to train the model and thereby fine-tune the BERT transformer, all there is left to do is to invoke the train method."],"metadata":{"id":"5Tq7vh952mEt"}},{"cell_type":"code","source":["model.train()"],"metadata":{"id":"v3CkJ_f33Jda"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note: this will take some time depending on the dimensions of your machine (if you want to skip training, you can go ahead and use one of the precooked models, that NERDA ships with).\n","And that is all there is to it. We have now fine-tuned our very own state-of-the-art BERT-based model for NER.\n","Let us see how the model performs (by means of F1-scores) on an independent test set."],"metadata":{"id":"8N7-bBmT3Ka_"}},{"cell_type":"code","source":["test = get_conll_data('test')\n","model.evaluate_performance(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"id":"G-UKCkYM3O9H","executionInfo":{"status":"ok","timestamp":1642421280448,"user_tz":300,"elapsed":1219901,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"0c0d35b5-e4c4-40cf-f076-8b7d3b389666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #202 length 139 exceeds max_len 128 and has been truncated\n","  warnings.warn(msg)\n","/usr/local/lib/python3.7/dist-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n","  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n","/usr/local/lib/python3.7/dist-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n","  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n","/usr/local/lib/python3.7/dist-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n","  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-84b95a7c-28c3-436a-b021-f1f8ddc26120\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Level</th>\n","      <th>F1-Score</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>B-PER</td>\n","      <td>0.006356</td>\n","      <td>0.022059</td>\n","      <td>0.003713</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I-PER</td>\n","      <td>0.019063</td>\n","      <td>0.010660</td>\n","      <td>0.090043</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>B-ORG</td>\n","      <td>0.009494</td>\n","      <td>0.010007</td>\n","      <td>0.009031</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I-ORG</td>\n","      <td>0.001609</td>\n","      <td>0.001036</td>\n","      <td>0.003593</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>B-LOC</td>\n","      <td>0.005979</td>\n","      <td>0.003982</td>\n","      <td>0.011998</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>I-LOC</td>\n","      <td>0.017797</td>\n","      <td>0.009046</td>\n","      <td>0.546875</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>B-MISC</td>\n","      <td>0.013544</td>\n","      <td>0.014354</td>\n","      <td>0.012821</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>I-MISC</td>\n","      <td>0.007528</td>\n","      <td>0.003842</td>\n","      <td>0.185185</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AVG_MICRO</td>\n","      <td>0.012466</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AVG_MICRO</td>\n","      <td>0.010171</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84b95a7c-28c3-436a-b021-f1f8ddc26120')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-84b95a7c-28c3-436a-b021-f1f8ddc26120 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-84b95a7c-28c3-436a-b021-f1f8ddc26120');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       Level  F1-Score  Precision    Recall\n","0      B-PER  0.006356   0.022059  0.003713\n","1      I-PER  0.019063   0.010660  0.090043\n","2      B-ORG  0.009494   0.010007  0.009031\n","3      I-ORG  0.001609   0.001036  0.003593\n","4      B-LOC  0.005979   0.003982  0.011998\n","5      I-LOC  0.017797   0.009046  0.546875\n","6     B-MISC  0.013544   0.014354  0.012821\n","7     I-MISC  0.007528   0.003842  0.185185\n","0  AVG_MICRO  0.012466        NaN       NaN\n","0  AVG_MICRO  0.010171        NaN       NaN"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["‘AVG_MICRO’: the micro-averaged F1-score across entity tags.\n","As you see, performance looks great.\n","We can now use the model for identifying named-entities in new texts, i.e."],"metadata":{"id":"6YSK94p88FJq"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oKRQY1J8VvY","executionInfo":{"status":"ok","timestamp":1642421386102,"user_tz":300,"elapsed":717,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"e1b9ec03-8bda-4fb5-f2a5-8587a203a651"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["model.predict_text('Cristiano Ronaldo plays for Juventus FC')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5I55ZfK8H5E","executionInfo":{"status":"ok","timestamp":1642421396461,"user_tz":300,"elapsed":813,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"d23f7a0c-1841-4c61-834f-152632e9f4ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([['Cristiano', 'Ronaldo', 'plays', 'for', 'Juventus', 'FC']],\n"," [['I-PER', 'I-LOC', 'I-PER', 'I-PER', 'I-PER', 'I-PER']])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["The model (correctly) identifies ‘Cristiano Ronaldo’ (football player) as a person and ‘Juventus FC’ (football club) as an organization."],"metadata":{"id":"vBMydvWf8qnY"}},{"cell_type":"markdown","source":["now lets look at another form of NER tuning we can do with BERT "],"metadata":{"id":"-qnybgtK8wg2"}},{"cell_type":"markdown","source":["## **Fine-tuning BERT for named-entity recognition**\n","\n","In this notebook, we are going to use **BertForTokenClassification** which is included in the [Transformers library](https://github.com/huggingface/transformers) by HuggingFace. This model has BERT as its base architecture, with a token classification head on top, allowing it to make predictions at the token level, rather than the sequence level. Named entity recognition is typically treated as a token classification problem, so that's what we are going to use it for.\n","\n","This tutorial uses the idea of **transfer learning**, i.e. first pretraining a large neural network in an unsupervised way, and then fine-tuning that neural network on a task of interest. In this case, BERT is a neural network pretrained on 2 tasks: masked language modeling and next sentence prediction. Now, we are going to fine-tune this network on a NER dataset. Fine-tuning is supervised learning, so this means we will need a labeled dataset.\n","\n","If you want to know more about BERT, I suggest the following resources:\n","* the original [paper](https://arxiv.org/abs/1810.04805)\n","* Jay Allamar's [blog post](http://jalammar.github.io/illustrated-bert/) as well as his [tutorial](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)\n","* Chris Mccormick's [Youtube channel](https://www.youtube.com/channel/UCoRX98PLOsaN8PtekB9kWrw)\n","* Abbishek Kumar Mishra's [Youtube channel](https://www.youtube.com/user/abhisheksvnit)\n","\n","The following notebook largely follows the same structure as the tutorials by Abhishek Kumar Mishra. For his tutorials on the Transformers library, see his [Github repository](https://github.com/abhimishra91/transformers-tutorials).\n","\n","NOTE: this notebook assumes basic knowledge about deep learning, BERT, and native PyTorch. If you want to learn more Python, deep learning and PyTorch, I highly recommend cs231n by Stanford University and the FastAI course by Jeremy Howard et al. Both are freely available on the web.  \n","\n","Now, let's move on to the real stuff!\n","<br/>\n","<br/>\n","Orginal content source -\n","https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb \n","<br/>\n","Related Content Sub Source 1\n","https://colab.research.google.com/drive/14rYdqGAXJhwVzslXT4XIwNFBwkmBWdVV\n","<br/>\n","Related Content Sub Source 2\n","https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/"],"metadata":{"id":"pv40XB9vsrwN"}},{"cell_type":"markdown","source":["#### **Importing Python Libraries and preparing the environment**\n","\n","This notebook assumes that you have the following libraries installed:\n","* pandas\n","* numpy\n","* sklearn\n","* pytorch\n","* transformers\n","* seqeval\n","\n","As we are running this in Google Colab, the only libraries we need to additionally install are transformers and seqeval (GPU version):"],"metadata":{"id":"XhZwPW5J-dQA"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"TcCX5yhrsqQD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642577929628,"user_tz":300,"elapsed":6688,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"3deb7626-1b98-4929-8ade-99eff17ad6dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.0.1\n","  Downloading transformers-3.0.1-py3-none-any.whl (757 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 40.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 48.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 327 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 409 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 419 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 430 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 440 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 491 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 501 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 512 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 532 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 552 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 604 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 624 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 634 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 645 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 655 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 665 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 696 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 706 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 716 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 727 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 737 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 747 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757 kB 30.6 MB/s \n","\u001b[?25hCollecting seqeval[gpu]\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (4.62.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 59.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (2.23.0)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 79.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (1.19.5)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (3.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.1) (3.0.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (7.1.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=e9c34cc585038d935bb0de863d9aca2aba1e18f38959f96e70483b16164d96f9\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: tokenizers, seqeval, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 seqeval-1.2.2 tokenizers-0.8.0rc4 transformers-3.0.1\n"]}],"source":["!pip install transformers==3.0.1 seqeval[gpu]"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"],"metadata":{"id":"c_naxt3s-kdm","executionInfo":{"status":"ok","timestamp":1642577937115,"user_tz":300,"elapsed":7496,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["As deep learning can be accellerated a lot using a GPU instead of a CPU, make sure you can run this notebook in a GPU runtime (which Google Colab provides for free! - check \"Runtime\" - \"Change runtime type\" - and set the hardware accelerator to \"GPU\").\n","\n","We can set the default device to GPU using the following code (if it prints \"cuda\", it means the GPU has been recognized):"],"metadata":{"id":"zNlhR6js_csu"}},{"cell_type":"code","source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MB78u5QY_I56","executionInfo":{"status":"ok","timestamp":1642577937116,"user_tz":300,"elapsed":23,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"06d760bf-9ec1-4375-de73-6518bcc5af0f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["Downloading and preprocessing the data\n","Named entity recognition (NER) uses a specific annotation scheme, which is defined (at least for European languages) at the word level. An annotation scheme that is widely used is called IOB-tagging, which stands for Inside-Outside-Beginning. Each tag indicates whether the corresponding word is inside, outside or at the beginning of a specific named entity. The reason this is used is because named entities usually comprise more than 1 word.\n","\n","Let's have a look at an example. If you have a sentence like \"Barack Obama was born in Hawaï\", then the corresponding tags would be [B-PERS, I-PERS, O, O, O, B-GEO]. B-PERS means that the word \"Barack\" is the beginning of a person, I-PERS means that the word \"Obama\" is inside a person, \"O\" means that the word \"was\" is outside a named entity, and so on. So one typically has as many tags as there are words in a sentence.\n","\n","So if you want to train a deep learning model for NER, it requires that you have your data in this IOB format (or similar formats such as BILOU). There exist many annotation tools which let you create these kind of annotations automatically (such as Spacy's Prodigy, Tagtog or Doccano). You can also use Spacy's biluo_tags_from_offsets function to convert annotations at the character level to IOB format.\n","\n","Here, we will use a NER dataset from Kaggle that is already in IOB format. One has to go to this web page, download the dataset, unzip it, and upload the csv file to this notebook. Let's print out the first few rows of this csv file:"],"metadata":{"id":"N9z33VyC_0e_"}},{"cell_type":"markdown","source":["https://www.kaggle.com/namanj27/ner-dataset"],"metadata":{"id":"KyVNmh9q_-38"}},{"cell_type":"code","source":["data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"W90JqDnI_jwo","executionInfo":{"status":"ok","timestamp":1642577937621,"user_tz":300,"elapsed":526,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"286f407c-0cc2-4132-f9d0-90ecd6fa6506"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9a27d389-1835-441d-8716-174032eaa459\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a27d389-1835-441d-8716-174032eaa459')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9a27d389-1835-441d-8716-174032eaa459 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9a27d389-1835-441d-8716-174032eaa459');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Let's check how many sentences and words (and corresponding tags) there are in this dataset:"],"metadata":{"id":"aM9ZRalRAmHI"}},{"cell_type":"code","source":["data.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhSe5FZUAiS7","executionInfo":{"status":"ok","timestamp":1642577937800,"user_tz":300,"elapsed":9,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"72863323-bac4-475b-d83f-3b42d97f8d2f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentence #      47959\n","Word          1048575\n","POS           1048575\n","Tag           1048575\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["As we can see, there are approximately 48,000 sentences in the dataset, comprising more than 1 million words and tags (quite huge!). This corresponds to approximately 20 words per sentence.\n","\n","Let's have a look at the different NER tags, and their frequency:"],"metadata":{"id":"MLYsyla2Ap7E"}},{"cell_type":"code","source":["print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n","frequencies = data.Tag.value_counts()\n","frequencies"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQhR03I3Aoux","executionInfo":{"status":"ok","timestamp":1642577937973,"user_tz":300,"elapsed":179,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"5cd225eb-4246-4c32-eaf3-069fdc241e94"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of tags: 17\n"]},{"output_type":"execute_result","data":{"text/plain":["O        887908\n","B-geo     37644\n","B-tim     20333\n","B-org     20143\n","I-per     17251\n","B-per     16990\n","I-org     16784\n","B-gpe     15870\n","I-geo      7414\n","I-tim      6528\n","B-art       402\n","B-eve       308\n","I-art       297\n","I-eve       253\n","B-nat       201\n","I-gpe       198\n","I-nat        51\n","Name: Tag, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["There are 8 category tags, each with a \"beginning\" and \"inside\" variant, and the \"outside\" tag. It is not really clear what these tags mean - \"geo\" probably stands for geographical entity, \"gpe\" for geopolitical entity, and so on. They do not seem to correspond with what the publisher says on Kaggle. Some tags seem to be underrepresented. Let's print them by frequency (highest to lowest):"],"metadata":{"id":"LFF2r3_2BBZ-"}},{"cell_type":"code","source":["tags = {}\n","for tag, count in zip(frequencies.index, frequencies):\n","    if tag != \"O\":\n","        if tag[2:5] not in tags.keys():\n","            tags[tag[2:5]] = count\n","        else:\n","            tags[tag[2:5]] += count\n","    continue\n","\n","print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEdf09abA8LF","executionInfo":{"status":"ok","timestamp":1642577937975,"user_tz":300,"elapsed":14,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"27e06769-525f-42c7-c31a-2df19f6dd970"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"]}]},{"cell_type":"markdown","source":["Let's remove \"art\", \"eve\" and \"nat\" named entities, as performance on them will probably be not comparable to the other named entities."],"metadata":{"id":"urBmtRLEBN3j"}},{"cell_type":"code","source":["entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n","data = data[~data.Tag.isin(entities_to_remove)]\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Gd9YtJXxBHMR","executionInfo":{"status":"ok","timestamp":1642577938135,"user_tz":300,"elapsed":169,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"38648c2e-0ea3-4e32-a35b-9da57c2e805b"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8e71fac1-1602-4f52-a46c-eef1123c810e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e71fac1-1602-4f52-a46c-eef1123c810e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8e71fac1-1602-4f52-a46c-eef1123c810e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8e71fac1-1602-4f52-a46c-eef1123c810e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["We create 2 dictionaries: one that maps individual tags to indices, and one that maps indices to their individual tags. This is necessary in order to create the labels (as computers work with numbers = indices, rather than words = tags) - see further in this notebook."],"metadata":{"id":"lFPZT_DSBbia"}},{"cell_type":"code","source":["labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n","ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n","labels_to_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXjbtWhCBTCL","executionInfo":{"status":"ok","timestamp":1642577938137,"user_tz":300,"elapsed":11,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"3ab2257c-850c-46fc-b13b-582568bd310b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'B-geo': 1,\n"," 'B-gpe': 2,\n"," 'B-org': 5,\n"," 'B-per': 3,\n"," 'B-tim': 7,\n"," 'I-geo': 4,\n"," 'I-gpe': 9,\n"," 'I-org': 6,\n"," 'I-per': 8,\n"," 'I-tim': 10,\n"," 'O': 0}"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["As we can see, there are now only 10 different NER tags.\n","\n","Now, we have to ask ourself the question: what is a training example in the case of NER, which is provided in a single forward pass? A training example is typically a sentence, with corresponding IOB tags. Let's group the words and corresponding tags by sentence:"],"metadata":{"id":"xQjS6Z8EBk9I"}},{"cell_type":"code","source":["# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n","data = data.fillna(method='ffill')\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"yyOwl19ABhcF","executionInfo":{"status":"ok","timestamp":1642577938326,"user_tz":300,"elapsed":197,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"37bff22c-e9f4-4991-cc96-1670f1e06201"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-fce94f14-7db1-478e-a67b-76af8933fc31\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fce94f14-7db1-478e-a67b-76af8933fc31')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fce94f14-7db1-478e-a67b-76af8933fc31 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fce94f14-7db1-478e-a67b-76af8933fc31');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1  Sentence: 1             of   IN   O\n","2  Sentence: 1  demonstrators  NNS   O\n","3  Sentence: 1           have  VBP   O\n","4  Sentence: 1        marched  VBN   O"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# let's create a new column called \"sentence\" which groups the words by sentence \n","data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n","\n","# let's also create a new column called \"word_labels\" which groups the tags by sentence \n","data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n","\n","\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"id":"AW-xv1IQBqK3","executionInfo":{"status":"ok","timestamp":1642578027544,"user_tz":300,"elapsed":89230,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"fa84005f-afc9-4fc8-b661-ae97f9c3cb2b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6a8c4de9-305e-4a70-925c-2a519ac03dc6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a8c4de9-305e-4a70-925c-2a519ac03dc6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6a8c4de9-305e-4a70-925c-2a519ac03dc6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6a8c4de9-305e-4a70-925c-2a519ac03dc6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Sentence #  ...                                        word_labels\n","0  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","1  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","2  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","3  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","4  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Let's only keep the \"sentence\" and \"word_labels\" columns, and drop duplicates:"],"metadata":{"id":"rh1UPovPCa7i"}},{"cell_type":"code","source":["data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"n4Hw5qCTB2Ue","executionInfo":{"status":"ok","timestamp":1642578028088,"user_tz":300,"elapsed":553,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"c01e1fe8-5241-4700-cb55-4c23b121cb80"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6f3a24f0-4a24-4b1a-adbc-a92a3c71fa8c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Families of soldiers killed in the conflict jo...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>They marched from the Houses of Parliament to ...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Police put the number of marchers at 10,000 wh...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The protest comes on the eve of the annual con...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f3a24f0-4a24-4b1a-adbc-a92a3c71fa8c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f3a24f0-4a24-4b1a-adbc-a92a3c71fa8c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f3a24f0-4a24-4b1a-adbc-a92a3c71fa8c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                            sentence                                        word_labels\n","0  Thousands of demonstrators have marched throug...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","1  Families of soldiers killed in the conflict jo...  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...\n","2  They marched from the Houses of Parliament to ...                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O\n","3  Police put the number of marchers at 10,000 wh...                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n","4  The protest comes on the eve of the annual con...  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,..."]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["next chek the length"],"metadata":{"id":"QPFIrT09Ci1P"}},{"cell_type":"code","source":["len(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"af8dO3kVCdaq","executionInfo":{"status":"ok","timestamp":1642578028090,"user_tz":300,"elapsed":22,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"2c211749-5b3a-4cc2-d43d-2c0ed1cc1c42"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["47571"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Let's verify that a random sentence and its corresponding tags are correct:"],"metadata":{"id":"zMNPiSBLCprU"}},{"cell_type":"code","source":["data.iloc[41].sentence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"a0tg90KqClVa","executionInfo":{"status":"ok","timestamp":1642578028094,"user_tz":300,"elapsed":22,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"ffa27ef7-b32d-45f2-844e-ee5a3e272498"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Bedfordshire police said Tuesday that Omar Khayam was arrested in Bedford for breaching the conditions of his parole .'"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["data.iloc[41].word_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Z3PLC--4CtJ_","executionInfo":{"status":"ok","timestamp":1642578028095,"user_tz":300,"elapsed":21,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"04e8d9cc-b6a9-4d4c-e4ec-bcaa10ead12e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["##Preparing the dataset and dataloader\n","Now that our data is preprocessed, we can turn it into PyTorch tensors such that we can provide it to the model. Let's start by defining some key variables that will be used later on in the training/evaluation process:\n","\n","[ ]\n"],"metadata":{"id":"ABKiehGcC0_V"}},{"cell_type":"code","source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","MAX_GRAD_NORM = 10\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["54a70952f63541eaa8397b23d9171a27","03ad2b9908ca47f6973a8c86a2225fe3","9bfe8b81bc9d46908592bef52924ca92","61846d244f2c4a59bd4e3a0f658044eb","0e3298d501e14660b768145d92aa9f79","d494d647f4c34014a106f7bf40e91d1c","44f937915cd14d50990af7f2169fe73a","21d39d1c1d2c4a0494dde2437fd52519","892d735c68d2482191f9722db25a404b","5d131328414241ee99e084fbcd6dd84b","47a7da967e3d485f84eee8ba49d84ca8"]},"id":"uQXS6X6VCwMX","executionInfo":{"status":"ok","timestamp":1642578028274,"user_tz":300,"elapsed":198,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"6d426b12-69c4-4fcc-d3a2-19de4b3676a8"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54a70952f63541eaa8397b23d9171a27","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":["A tricky part of NER with BERT is that BERT relies on wordpiece tokenization, rather than word tokenization. This means that we should also define the labels at the wordpiece-level, rather than the word-level!\n","\n","For example, if you have word like \"Washington\" which is labeled as \"b-gpe\", but it gets tokenized to \"Wash\", \"##ing\", \"##ton\", then one approach could be to handle this by only train the model on the tag labels for the first word piece token of a word (i.e. only label \"Wash\" with \"b-gpe\"). This is what was done in the original BERT paper, see Github discussion here.\n","\n","Note that this is a design decision. You could also decide to propagate the original label of the word to all of its word pieces and let the model train on this. In that case, the model should be able to produce the correct labels for each individual wordpiece. This was done in this NER tutorial with BERT. Another design decision could be to give the first wordpiece of each word the original word label, and then use the label “X” for all subsequent subwords of that word. All of them seem to lead to good performance.\n","\n","Below, we define a regular PyTorch dataset class (which transforms examples of a dataframe to PyTorch tensors). Here, each sentence gets tokenized, the special tokens that BERT expects are added, the tokens are padded or truncated based on the max length of the model, the attention mask is created and the labels are created based on the dictionary which we defined above. Word pieces that should be ignored have a label of -100 (which is the default ignore_index of PyTorch's CrossEntropyLoss).\n","\n","For more information about BERT's inputs, see here."],"metadata":{"id":"ZXFeJKLrDAR3"}},{"cell_type":"code","source":["class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels \n","        sentence = self.data.sentence[index].strip().split()  \n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_pretokenized=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [labels_to_ids[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"metadata":{"id":"0yNxlE2SC5bX","executionInfo":{"status":"ok","timestamp":1642578028277,"user_tz":300,"elapsed":26,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Now, based on the class we defined above, we can create 2 datasets, one for training and one for testing. Let's use a 80/20 split:"],"metadata":{"id":"FnapwZjFDw1e"}},{"cell_type":"code","source":["train_size = 0.8\n","train_dataset = data.sample(frac=train_size,random_state=200)\n","test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(data.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w35KqmbtDQqr","executionInfo":{"status":"ok","timestamp":1642578028283,"user_tz":300,"elapsed":31,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"9b6d6100-abc8-45f0-e40c-8e67a6fac1f7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (47571, 2)\n","TRAIN Dataset: (38057, 2)\n","TEST Dataset: (9514, 2)\n"]}]},{"cell_type":"markdown","source":["Let's have a look at the first training example:"],"metadata":{"id":"BAzY8w-IEUw5"}},{"cell_type":"code","source":["print(training_set[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmE4Ke56D1K0","executionInfo":{"status":"ok","timestamp":1642578028449,"user_tz":300,"elapsed":33,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"e30b99a9-c8d4-4c0c-dccb-e1e9be953d2d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([  101, 23564, 21030,  2099,  4967,  2001,  9388,  1011,  6109,  2005,\n","         2634,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'offset_mapping': tensor([[0, 0],\n","        [0, 2],\n","        [2, 5],\n","        [5, 6],\n","        [0, 4],\n","        [0, 3],\n","        [0, 3],\n","        [3, 4],\n","        [4, 6],\n","        [0, 3],\n","        [0, 5],\n","        [0, 1],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0]]), 'labels': tensor([-100,    3, -100, -100,    8,    0,    0, -100, -100,    0,    1,    0,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100])}\n"]}]},{"cell_type":"markdown","source":["Let's verify that the input ids and corresponding targets are correct:"],"metadata":{"id":"BDEIQQLREoA7"}},{"cell_type":"code","source":["for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n","  print('{0:10}  {1}'.format(token, label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSDRUilrEalc","executionInfo":{"status":"ok","timestamp":1642578028450,"user_tz":300,"elapsed":15,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"bb8acc79-357d-49c9-bee2-12fb0fe81d00"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]       -100\n","za          3\n","##hee       -100\n","##r         -100\n","khan        8\n","was         0\n","mar         0\n","-           -100\n","93          -100\n","for         0\n","india       1\n",".           0\n","[SEP]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n"]}]},{"cell_type":"markdown","source":["Now, let's define the corresponding PyTorch dataloaders:"],"metadata":{"id":"SLLoEpg9HmMJ"}},{"cell_type":"code","source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"metadata":{"id":"Wip8_G1oEq5q","executionInfo":{"status":"ok","timestamp":1642578069832,"user_tz":300,"elapsed":134,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["#Defining the model\n","Here we define the model, BertForTokenClassification, and load it with the pretrained weights of \"bert-base-uncased\". The only thing we need to additionally specify is the number of labels (as this will determine the architecture of the classification head).\n","\n","Note that only the base layers are initialized with the pretrained weights. The token classification head of top has just randomly initialized weights, which we will train, together with the pretrained weights, using our labelled dataset. This is also printed as a warning when you run the code cell below.\n","\n","Then, we move the model to the GPU."],"metadata":{"id":"ffSGbhQ_SYKP"}},{"cell_type":"code","source":["model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["027c9fb342f94f508991bbda641476d5","9a7fcc16b08a4dc782d8b53f0a8f1495","591df1ada8614553a82b66972d56f426","2d8ca72fb6c240f2a166ed9a6c05ec5a","0ea6a461017c45688d793d2a62692f43","621bb7f851594dfa96b620586ba7d856","6c8bf42b7e814b56a796ba6bd839ad02","f0ac25364149410385f8bbd4ef6513a3","641b4b5a24874b75b3fe19d625461fba","ddc9ac01016c4d3e9d476e896f607897","fe55b84eb2c04f25a99fbb2314e7e672","8574e59bd09d41d0a1cfdd0ca05d5c44","cffb4cee9a8949f1a0c3945f23f22c75","69a5375a3b5248b68f3d6efc7050ee46","11e5602d71ef4783b59b549cdb3dccfd","26d3ee2a0c534a019dd62906cc978473","ed69e9a0915646f2b2d876d5de86bbfe","a3f525956be142d491fa5e0d78d8590d","96f1cedad03a407eaa5fe6ae7e6b0485","29d658a89ae64f4e831b34f1aaf5afcc","6b8d068030e743939b0138bb26a53388","f3e782a62c054a529aa386624ec515e8"]},"id":"y7a2kGWUSEet","executionInfo":{"status":"ok","timestamp":1642578222243,"user_tz":300,"elapsed":21373,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"9a5815a5-cce4-4e62-ba44-ce03d1ee5f63"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"027c9fb342f94f508991bbda641476d5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8574e59bd09d41d0a1cfdd0ca05d5c44","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Training the model\n","Before training the model, let's perform a sanity check, which I learned thanks to Andrej Karpathy's wonderful cs231n course at Stanford (see also his blog post about debugging neural networks). The initial loss of your model should be close to -ln(1/number of classes) = -ln(1/17) = 2.83.\n","\n","Why? Because we are using cross entropy loss. The cross entropy loss is defined as -ln(probability score of the model for the correct class). In the beginning, the weights are random, so the probability distribution for all of the classes for a given token will be uniform, meaning that the probability for the correct class will be near 1/17. The loss for a given token will thus be -ln(1/17). As PyTorch's CrossEntropyLoss (which is used by BertForTokenClassification) uses mean reduction by default, it will compute the mean loss for each of the tokens in the sequence for which a label is provided.\n","\n","Let's verify this:"],"metadata":{"id":"SxKcOrksSwrI"}},{"cell_type":"code","source":["inputs = training_set[2]\n","input_ids = inputs[\"input_ids\"].unsqueeze(0)\n","attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n","labels = inputs[\"labels\"].unsqueeze(0)\n","\n","input_ids = input_ids.to(device)\n","attention_mask = attention_mask.to(device)\n","labels = labels.to(device)\n","\n","outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","initial_loss = outputs[0]\n","initial_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEXYNbzbSkgc","executionInfo":{"status":"ok","timestamp":1642578314888,"user_tz":300,"elapsed":329,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"fad69c6d-14aa-47f8-9a78-1835dd8c3238"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.2921, device='cuda:0', grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["This looks good. Let's also verify that the logits of the neural network have a shape of (batch_size, sequence_length, num_labels):"],"metadata":{"id":"E1Uij_T3THGa"}},{"cell_type":"code","source":["tr_logits = outputs[1]\n","tr_logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMEZDTdwTAQs","executionInfo":{"status":"ok","timestamp":1642578386102,"user_tz":300,"elapsed":203,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"35103040-d829-4ee7-f536-80faa285668d"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128, 11])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Next, we define the optimizer. Here, we are just going to use Adam with a default learning rate. One can also decide to use more advanced ones such as AdamW (Adam with weight decay fix), which is included in the Transformers repository, and a learning rate scheduler, but we are not going to do that here.\n","\n"],"metadata":{"id":"DuvPsJGNTiwr"}},{"cell_type":"code","source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"_L7_TuwbTRrJ","executionInfo":{"status":"ok","timestamp":1642578511105,"user_tz":300,"elapsed":3,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Now let's define a regular PyTorch training function. It is partly based on a really good repository about multilingual NER."],"metadata":{"id":"schdnmopT22e"}},{"cell_type":"code","source":["# Defining the training function on the 80% of the dataset for tuning the bert model\n","def train(epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"metadata":{"id":"9CAgoW5iTwMV","executionInfo":{"status":"ok","timestamp":1642578575460,"user_tz":300,"elapsed":136,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["\n","And let's train the model!"],"metadata":{"id":"wY_comoVUDxR"}},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    try:\n","      train(epoch)\n","    except:\n","      continue"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"s63WqDOdT_5k","executionInfo":{"status":"error","timestamp":1642579202345,"user_tz":300,"elapsed":576322,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"2f4c05a2-327f-4986-f62f-2bb180107b29"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3038878440856934\n","Training loss per 100 training steps: 0.7857694596347242\n","Training loss per 100 training steps: 0.5702719339980414\n","Training loss per 100 training steps: 0.47753915698128285\n","Training loss per 100 training steps: 0.41867291533441614\n","Training loss per 100 training steps: 0.3732656849187589\n","Training loss per 100 training steps: 0.341843023770698\n","Training loss per 100 training steps: 0.3219679711099592\n","Training loss per 100 training steps: 0.30251329642291486\n","Training loss per 100 training steps: 0.28452939326801524\n","Training loss per 100 training steps: 0.2716658317300674\n","Training loss per 100 training steps: 0.2605105994470573\n","Training loss per 100 training steps: 0.2519529462442249\n","Training loss per 100 training steps: 0.2453950600795946\n","Training loss per 100 training steps: 0.23860633629856154\n","Training loss per 100 training steps: 0.23235308578756603\n","Training loss per 100 training steps: 0.22718238961190068\n","Training loss per 100 training steps: 0.22196441554414575\n","Training loss per 100 training steps: 0.21667708106378278\n","Training loss per 100 training steps: 0.21180573860545893\n","Training loss per 100 training steps: 0.20836728809099794\n","Training loss per 100 training steps: 0.20528079954612963\n","Training loss per 100 training steps: 0.2014476661081648\n","Training loss per 100 training steps: 0.1989080675453456\n","Training loss per 100 training steps: 0.19593514909545756\n","Training loss per 100 training steps: 0.1931238724825541\n","Training loss per 100 training steps: 0.19027877783600453\n","Training loss per 100 training steps: 0.18778973606476124\n","Training loss per 100 training steps: 0.1858680617725573\n","Training loss per 100 training steps: 0.18360577321841526\n","Training loss per 100 training steps: 0.1815771612441754\n","Training loss per 100 training steps: 0.18034501713575957\n","Training loss per 100 training steps: 0.17883900700512922\n","Training loss per 100 training steps: 0.17704150080398715\n","Training loss per 100 training steps: 0.1755602804886961\n","Training loss per 100 training steps: 0.1739592465818922\n","Training loss per 100 training steps: 0.17243843432994324\n","Training loss per 100 training steps: 0.17134470889023717\n","Training loss per 100 training steps: 0.1701072141844451\n","Training loss per 100 training steps: 0.16897459757774286\n","Training loss per 100 training steps: 0.1676093196906978\n","Training loss per 100 training steps: 0.16688663572989543\n","Training loss per 100 training steps: 0.16563617326678357\n","Training loss per 100 training steps: 0.16447923928035835\n","Training loss per 100 training steps: 0.16335067695801453\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-8d08785e3057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training epoch: {epoch + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-f4ae8fcedce9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-e0f6293f7650>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# overwrite label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mencoded_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","source":["#Evaluating the model\n","Now that we've trained our model, we can evaluate its performance on the held-out test set (which is 20% of the data). Note that here, no gradient updates are performed, the model just outputs its logits."],"metadata":{"id":"9QI9UArjbNbs"}},{"cell_type":"code","source":["def valid(model, testing_loader):\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [ids_to_labels[id.item()] for id in eval_labels]\n","    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions"],"metadata":{"id":"qsyRsfFuUMTh","executionInfo":{"status":"ok","timestamp":1642580492640,"user_tz":300,"elapsed":136,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["As we can see below, performance is quite good! Accuracy on the test test is > 93%."],"metadata":{"id":"sGStSY5VbcfG"}},{"cell_type":"code","source":["labels, predictions = valid(model, testing_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4NoIsOlbT_D","executionInfo":{"status":"ok","timestamp":1642580642784,"user_tz":300,"elapsed":95567,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"71cf42b1-4a30-4487-f70f-74ec5b8a03ec"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss per 100 evaluation steps: 0.27502426505088806\n","Validation loss per 100 evaluation steps: 0.11572727056031143\n","Validation loss per 100 evaluation steps: 0.11341124264852362\n","Validation loss per 100 evaluation steps: 0.1182622583737702\n","Validation loss per 100 evaluation steps: 0.12028815121713043\n","Validation loss per 100 evaluation steps: 0.1169979839906735\n","Validation loss per 100 evaluation steps: 0.12101101262657438\n","Validation loss per 100 evaluation steps: 0.11934100189077676\n","Validation loss per 100 evaluation steps: 0.11939847036489383\n","Validation loss per 100 evaluation steps: 0.11725372019315994\n","Validation loss per 100 evaluation steps: 0.11576790939116935\n","Validation loss per 100 evaluation steps: 0.115988444145384\n","Validation loss per 100 evaluation steps: 0.1135722917553947\n","Validation loss per 100 evaluation steps: 0.11343974709652363\n","Validation loss per 100 evaluation steps: 0.11284261276717959\n","Validation loss per 100 evaluation steps: 0.11257241180967471\n","Validation loss per 100 evaluation steps: 0.1127605873450848\n","Validation loss per 100 evaluation steps: 0.11301571750515296\n","Validation loss per 100 evaluation steps: 0.1129936471185285\n","Validation loss per 100 evaluation steps: 0.11315521032917242\n","Validation loss per 100 evaluation steps: 0.11322945690977256\n","Validation loss per 100 evaluation steps: 0.11352196978963645\n","Validation loss per 100 evaluation steps: 0.11304092603120068\n","Validation loss per 100 evaluation steps: 0.11301435875002216\n","Validation loss per 100 evaluation steps: 0.11388889386398432\n","Validation loss per 100 evaluation steps: 0.11398313888417995\n","Validation loss per 100 evaluation steps: 0.11432457988737015\n","Validation loss per 100 evaluation steps: 0.11476742798634137\n","Validation loss per 100 evaluation steps: 0.1152380796769105\n","Validation loss per 100 evaluation steps: 0.11486009384325431\n","Validation loss per 100 evaluation steps: 0.1145519602803322\n","Validation loss per 100 evaluation steps: 0.1145507828850928\n","Validation loss per 100 evaluation steps: 0.11509701130228418\n","Validation loss per 100 evaluation steps: 0.11581815103329322\n","Validation loss per 100 evaluation steps: 0.11554277674558407\n","Validation loss per 100 evaluation steps: 0.11478365426112819\n","Validation loss per 100 evaluation steps: 0.11459552923450537\n","Validation loss per 100 evaluation steps: 0.11485900818826854\n","Validation loss per 100 evaluation steps: 0.11467593033570997\n","Validation loss per 100 evaluation steps: 0.11412714343080738\n","Validation loss per 100 evaluation steps: 0.1138076019755596\n","Validation loss per 100 evaluation steps: 0.11366090761368938\n","Validation loss per 100 evaluation steps: 0.11372705521803711\n","Validation loss per 100 evaluation steps: 0.11350951600770212\n","Validation loss per 100 evaluation steps: 0.11335037058243042\n","Validation loss per 100 evaluation steps: 0.11376202818651929\n","Validation loss per 100 evaluation steps: 0.11333566301884375\n","Validation loss per 100 evaluation steps: 0.11341693081880372\n","Validation Loss: 0.11347722134065821\n","Validation Accuracy: 0.9656136062132399\n"]}]},{"cell_type":"markdown","source":["However, the accuracy metric is misleading, as a lot of labels are \"outside\" (O), even after omitting predictions on the [PAD] tokens. What is important is looking at the precision, recall and f1-score of the individual tags. For this, we use the seqeval Python library:\n","\n"],"metadata":{"id":"ym0iYJeRcR6i"}},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","\n","#labels\n","#predictions\n","print(classification_report([labels], [predictions]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUy8QI4ibhWE","executionInfo":{"status":"ok","timestamp":1642581143402,"user_tz":300,"elapsed":3219,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"d5d7717c-8231-4c38-dc26-0fe22656b2f9"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         geo       0.82      0.87      0.84      7378\n","         gpe       0.88      0.94      0.91      3021\n","         org       0.60      0.59      0.60      3964\n","         per       0.72      0.81      0.77      3367\n","         tim       0.84      0.86      0.85      4070\n","\n","   micro avg       0.78      0.82      0.80     21800\n","   macro avg       0.77      0.81      0.79     21800\n","weighted avg       0.78      0.82      0.80     21800\n","\n"]}]},{"cell_type":"markdown","source":["Performance already seems quite good, but note that we've only trained for 1 epoch. An optimal approach would be to perform evaluation on a validation set while training to improve generalization."],"metadata":{"id":"r_4-GBU5d40x"}},{"cell_type":"markdown","source":["#Inference\n","The fun part is when we can quickly test the model on new, unseen sentences. Here, we use the prediction of the first word piece of every word (which is how the model was trained).\n","\n","In other words, the code below does not take into account when predictions of different word pieces that belong to the same word do not match."],"metadata":{"id":"hIwO48zid8PJ"}},{"cell_type":"code","source":["sentence = \"@HuggingFace is a company based in New York, but is also has employees working in Paris\"\n","\n","inputs = tokenizer(sentence.split(),\n","                    is_pretokenized=True, \n","                    return_offsets_mapping=True, \n","                    padding='max_length', \n","                    truncation=True, \n","                    max_length=MAX_LEN,\n","                    return_tensors=\"pt\")\n","\n","# move to gpu\n","ids = inputs[\"input_ids\"].to(device)\n","mask = inputs[\"attention_mask\"].to(device)\n","# forward pass\n","outputs = model(ids, attention_mask=mask)\n","logits = outputs[0]\n","\n","active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","\n","tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n","wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","\n","prediction = []\n","for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n","  #only predictions on first word pieces are important\n","  if mapping[0] == 0 and mapping[1] != 0:\n","    prediction.append(token_pred[1])\n","  else:\n","    continue\n","\n","print(sentence.split())\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtnSXf0OcWE4","executionInfo":{"status":"ok","timestamp":1642581214189,"user_tz":300,"elapsed":147,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"39829997-c191-463b-cba1-5a9a3a5004a0"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["['@HuggingFace', 'is', 'a', 'company', 'based', 'in', 'New', 'York,', 'but', 'is', 'also', 'has', 'employees', 'working', 'in', 'Paris']\n","['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo']\n"]}]},{"cell_type":"markdown","source":["#Saving the model for future use\n","Finally, let's save the vocabulary (.txt) file, model weights (.bin) and the model's configuration (.json) to a directory, so that both the tokenizer and model can be re-loaded using the from_pretrained() class method."],"metadata":{"id":"9HtbxK9PeI9U"}},{"cell_type":"code","source":["import os\n","\n","directory = \"./model\"\n","\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","# save vocabulary of the tokenizer\n","tokenizer.save_vocabulary(directory)\n","# save the model weights and its configuration file\n","model.save_pretrained(directory)\n","print('All files saved')\n","print('This tutorial is completed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiS4oPmSeEIl","executionInfo":{"status":"ok","timestamp":1642581258399,"user_tz":300,"elapsed":1828,"user":{"displayName":"Endless Void Studios","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM0px4L1cJJj8vWWaBsn3ckrGotkRLOR7v1gSu=s64","userId":"02023283266459455631"}},"outputId":"5ec014a1-027a-43be-de03-cc2e9ac03b33"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["All files saved\n","This tutorial is completed\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lgpGMqQVeOhY"},"execution_count":null,"outputs":[]}]}